{
 "cells": [
  {
   "source": [
    "## Randomized Algorithms\n",
    "While the previous definition of a profile matrix was that constructred by a collection of k-Motifs in DNA. For RAs, we need to define the k-Motifs as a function of an arbitrary profile matrix and DNA strings. \n",
    "\n",
    "We find the k-Motifs by using the profile matrix for each possible k-mer and selectnig the one that maximizes the score/most conserved motif. \n",
    "\n",
    "This can also repeat for the next motif selection: *Motifs(Profile(Motifs), DNA)* After this, we should compute the profile of these motifs hoping that this improved motif could better help select a motif. *Profile(Motifs(Profile(Motifs), DNA))*\n",
    "\n",
    "This process repeats -> this is what RandomizedMotifSearch does. The randomized element comes from selecting the initial collection of k-mers that form the profile matrix. \n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "def newneighbours(text, k):\n",
    "    return [text[i:i+k] for i in range(len(text) - (k-1))]\n",
    "\n",
    "def entropy_calc(counts):\n",
    "    base = np.nan_to_num(counts*np.log2((counts)))\n",
    "    sums = [-1 * sum(base[i]) for i in range(len(base))]\n",
    "    return sums\n",
    "    \n",
    "def text_counts(text, k, laplace=True): #after rewriting the count and profile method, I noticed the main flaw in the profile_dict calculations\n",
    "    if laplace == True:\n",
    "        init = 1\n",
    "    else:\n",
    "        init = 0\n",
    "\n",
    "    count_dict = {key: [init] * k for key in ['A', 'C', 'G', 'T']}\n",
    "\n",
    "    for row in text:\n",
    "        row = str(row)\n",
    "        for idx, nuc in enumerate(row):\n",
    "            count_dict[nuc][idx] += 1\n",
    "\n",
    "    profile_dict = {key: [i/(k-1+(init*len(text))) for i in value] for key, value in count_dict.items()} #here, we need to divide by the len(text) or t + k as it matches the laplace-init\n",
    "    di = list(count_dict.values())\n",
    "    \n",
    "    return count_dict, profile_dict, entropy_calc(np.asanyarray(di).transpose())\n",
    "\n",
    "def RandomInit(text, k, t):\n",
    "    all_patterns = [newneighbours(line, k) for line in text]\n",
    "    rand_idx = [random.randint(0, len(all_patterns[0])-1) for _ in range(t)]\n",
    "    \n",
    "    init_patterns = []\n",
    "    for idx, line in enumerate(all_patterns):\n",
    "       init_patterns.append(line[rand_idx[idx]])\n",
    "    \n",
    "    return init_patterns\n",
    "\n",
    "def ScorePattern(profile, pattern):\n",
    "    prod = 1\n",
    "    for idx, nuc in enumerate(pattern):\n",
    "        if nuc == '[' or nuc == ']':\n",
    "            pass\n",
    "        else:\n",
    "            prod *= profile[nuc][idx]\n",
    "    return [pattern, prod]\n",
    "    \n",
    "\n",
    "def ProfileProbable(profile, text, k):\n",
    "    most_probables = []\n",
    "    for line in text:\n",
    "        line_neighbours = newneighbours(line, k)\n",
    "        all_prods = dict(list(map(ScorePattern, [profile for _ in range(len(line_neighbours))], line_neighbours)))\n",
    "        vals = list(all_prods.values())\n",
    "        most_probables.append([[key for key in all_prods.keys() if all_prods[key] == max(vals)], max(vals)])\n",
    "    \n",
    "    return most_probables\n",
    "\n",
    "\n",
    "def RandomizedMotifSearch(DNA, k, t):\n",
    "    rand_init = RandomInit(DNA, k, t)\n",
    "    best_motifs = rand_init\n",
    "\n",
    "\n",
    "    while True:\n",
    "        _, profile, _ = text_counts(best_motifs, k, laplace=True)\n",
    "        most_prob = ProfileProbable(profile, DNA, k)\n",
    "        init_prob = [ScorePattern(profile, pattern) for pattern in best_motifs]\n",
    "        \n",
    "        if sum([i[1] for i in most_prob]) > sum([i[1] for i in init_prob]):\n",
    "            best_motifs = [i[0][0] for i in most_prob]\n",
    "        else:\n",
    "            return [best_motifs, sum([i[1] for i in most_prob])]\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1242,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[['AACGGCCA', 'AAGTGCCA', 'TAGTACCG', 'AAGTTTCA', 'ACGTGCAA'], 0.0011628401968068894]\n"
     ]
    }
   ],
   "source": [
    "betters = []\n",
    "DNA = ['CGCCCCTCTCGGGGGTGTTCAGTAAACGGCCA', 'GGGCGAGGTATGTGTAAGTGCCAAGGTGCCAG', 'TAGTACCGAGACCGAAAGAAGTATACAGGCGT', 'TAGATCAAGTTTCAGGTGCACGTCGGTGAACC', 'AATCCACCAGCTCCACGTGCAATGTTGGCCTA']\n",
    "k = 8\n",
    "t = len(DNA)\n",
    "\n",
    "for _ in range(1000):\n",
    "    betters.append(RandomizedMotifSearch(DNA, k, t))\n",
    "\n",
    "scores = [i[1] for i in betters]\n",
    "main_idx = scores.index(max(scores))\n",
    "print(betters[main_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1244,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset_161_5 (8).txt', 'r') as sqinput:\n",
    "    sqinput = sqinput.read().splitlines()\n",
    "    params = [int(i) for i in sqinput[0].split(' ')]\n",
    "\n",
    "\n",
    "betters = []\n",
    "DNA = sqinput[1:]\n",
    "k = params[0]\n",
    "t = params[1]\n",
    "\n",
    "\n",
    "for i in range(1000):\n",
    "    betters.append(RandomizedMotifSearch(DNA, k, t))\n",
    "\n",
    "scores = [i[1] for i in betters]\n",
    "main_idx = scores.index(max(scores))\n",
    "print(betters[main_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1031,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CGTTTTTACTATCAT\nCGTCGACGTCAATAT\nCGTTCCCGTCATATT\nGCTTCCCGTCAATAG\nCGTTCCGAACAATAT\nCGTTCCCGCAGATAT\nCGTTCGGATCAATAT\nCAACCCCGTCAATAT\nGGTTCCCGTCAATCA\nCGTTCCCGTGTTTAT\nCGTTCCCCATAATAT\nCGTTCCGTCCAATAT\nCGTTTGGGTCAATAT\nCGTTCGTCTCAATAT\nCGTGTTCGTCAATAT\nTTGTCCCGTCAATAT\nCGCCGCCGTCAATAT\nCGTTGTGGTCAATAT\nCGTTCCCGTCAACCC\nCGTTCCCGTCGTAAT\n"
     ]
    }
   ],
   "source": [
    "better = betters[main_idx][0]\n",
    "for i in better:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1245,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# rand_init = RandomInit(DNA, k, t)\n",
    "# best_motifs = rand_init\n",
    "# _, profile, _ = text_counts(best_motifs, k, laplace=True)\n",
    "# most_prob = ProfileProbable(profile, DNA, k)\n",
    "# init_prob = [ScorePattern(profile, pattern) for pattern in best_motifs]\n",
    "\n",
    "# # print(sum([i[1] for i in most_prob]), sum([i[1] for i in init_prob]))\n",
    "\n",
    "# if sum([i[1] for i in most_prob]) > sum([i[1] for i in init_prob]):\n",
    "#     best_motifs = [i[0][0] for i in most_prob]\n",
    "# else:\n",
    "#     print(best_motifs, sum([i[1] for i in most_prob]))\n",
    "\n",
    "# # print(profile)\n",
    "# print(best_motifs)\n",
    "\n",
    "# _, profile, _ = text_counts(best_motifs, k, laplace=True)\n",
    "# # print(profile)\n",
    "# most_prob = ProfileProbable(profile, DNA, k)\n",
    "# init_prob = [ScorePattern(profile, pattern) for pattern in best_motifs]\n",
    "\n",
    "# # print(sum([i[1] for i in most_prob]), sum([i[1] for i in init_prob]))\n",
    "\n",
    "# print(most_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "randomer = lambda t: [random.random() for _ in range(t)]\n",
    "gibbs = lambda x: np.true_divide(np.array(randomer(x)), sum(np.array(randomer(x))))\n",
    "\n",
    "gibbs(2)\n",
    "\n",
    "def WeightedProbabilities(all_probs):\n",
    "    summed = sum(list(all_probs.values()))\n",
    "    \n",
    "    for idx, (key, val) in enumerate(all_probs.items()):\n",
    "        all_probs[key] = float(val/summed)\n",
    "    \n",
    "    return all_probs\n",
    "\n",
    "def NewScore(motifs):\n",
    "    score = 0\n",
    "    consensus = ConcensusString(motifs)\n",
    "    for i in range(len(motifs)):\n",
    "        score += NewHamming(consensus,motifs[i])\n",
    "    return score\n",
    "\n",
    "def ConcensusString(motifs):\n",
    "    k = len(motifs[0])\n",
    "    count = NewCount(motifs)\n",
    "    consensus = \"\"\n",
    "    for j in range(k):\n",
    "        M = 0\n",
    "        frequentSymbol = \"\"\n",
    "        for symbol in \"ACGT\":\n",
    "            if count[symbol][j] > M:\n",
    "                M = count[symbol][j]\n",
    "                frequentSymbol = symbol\n",
    "        consensus += frequentSymbol\n",
    "    return consensus\n",
    "\n",
    "def NewHamming(p, q):\n",
    "    count = 0\n",
    "    L = len(p)\n",
    "    for i in range(L):\n",
    "        if p[i] != q[i]:\n",
    "            count += 1\n",
    "    return count\n",
    "\n",
    "def NewCount(motifs):\n",
    "    count = {}\n",
    "    k = len(motifs[0])\n",
    "    for symbol in \"ACGT\":\n",
    "        count[symbol] = [] #Genero una lista para cada nucleotido en el set count\n",
    "        for j in range(k):\n",
    "            count[symbol].append(1) #a cada uno le pongo un 0\n",
    "    t = len(motifs)\n",
    "    for i in range(t):\n",
    "        for j in range(k):\n",
    "            symbol = motifs[i][j] #para el simbolo de esa posicion del motivo\n",
    "            count[symbol][j] += 1 #sumarle un 1 al set count en ese lugar\n",
    "    return count\n",
    "\n",
    "def BetterProbable(profile, line, k):\n",
    "    most_probables = []\n",
    "\n",
    "    line_neighbours = newneighbours(line, k)\n",
    "    all_prods = dict(list(map(ScorePattern, [profile for _ in range(len(line_neighbours))], line_neighbours)))\n",
    "    all_probs = WeightedProbabilities(all_prods)\n",
    "    vals = list(all_probs.values())\n",
    "\n",
    "    most_probables.append([[key for key in all_probs.keys() if all_probs[key] == max(vals)], max(vals)])\n",
    "\n",
    "    \n",
    "    return most_probables, all_probs\n",
    "\n",
    "def GibbsSampler(DNA, k, t, N):\n",
    "    rand_init = RandomInit(DNA, k, t)\n",
    "    best_motifs = rand_init\n",
    "    \n",
    "    for _ in range(N):\n",
    "        remove_line_idx = random.randint(0, t-1)\n",
    "\n",
    "        counts, profile_removed, _ = text_counts(best_motifs[:remove_line_idx] + best_motifs[remove_line_idx+1:], k, laplace=True)\n",
    "        most_probable, all_prods = BetterProbable(profile_removed, DNA[remove_line_idx], k)\n",
    "        final_appender = best_motifs[:]\n",
    "        # print(most_probable)\n",
    "        final_appender[remove_line_idx] = most_probable[0][0][0]\n",
    "        \n",
    "        final_score = NewScore(final_appender)\n",
    "        current_best_score = NewScore(best_motifs)\n",
    "\n",
    "\n",
    "\n",
    "        if final_score < current_best_score:\n",
    "            best_motifs = final_appender\n",
    "        else:\n",
    "            return best_motifs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1363,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset_163_4 (13).txt', 'r') as sqinput:\n",
    "    sqinput = sqinput.read().splitlines()\n",
    "    params = [int(i) for i in sqinput[0].split(' ')]\n",
    "\n",
    "DNA = sqinput[1:]\n",
    "k = params[0]\n",
    "t = params[1]\n",
    "N = params[2]\n",
    "\n",
    "N = 500\n",
    "\n",
    "# DNA = ['TTACCTTAAC', 'GATGTCTGTC', 'CCGGCGTTAG', 'CACTAACGAG', 'CGTCAGAGGT']\n",
    "# k = 4\n",
    "# t = len(DNA)\n",
    "# N = 100\n",
    "\n",
    "# GibbsSampler(DNA, k, t, N)\n",
    "\n",
    "\n",
    "# DNA = ['CGCCCCTCTCGGGGGTGTTCAGTAAACGGCCA', 'GGGCGAGGTATGTGTAAGTGCCAAGGTGCCAG', 'TAGTACCGAGACCGAAAGAAGTATACAGGCGT', 'TAGATCAAGTTTCAGGTGCACGTCGGTGAACC','AATCCACCAGCTCCACGTGCAATGTTGGCCTA']\n",
    "# k = 8\n",
    "# t = len(DNA)\n",
    "# N = 1000\n",
    "\n",
    "# GibbsSampler(DNA, k, t, N)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1371,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "AGCGCTGTGAGTGAG\nAGATCAGTGTGCAAG\nAATGCTACAGGTTTC\nTGCCCGGTCGCTAGG\nTAGGCTACCATTATG\nAAGACTGTGAATTTG\nAGATCTGCATAAAGG\nAACCCGAAATCTATG\nGGGCCTGTGATTAAG\nAGTAGGTTAACCCAG\nAAACCTGCATGAATG\nTTGGATGAAAGTATG\nACCGCGGCGAAAATC\nCACGCTATGTGAAAC\nAAATCGGCCACACAT\nAACCATGTTTGTTTC\nCCGCCGGTATCTCAC\nAAATCAGAGAATTAG\nTTGGCGAACTTTTCG\nATCGCGGAAAGTCCG\n142\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bestMotifs = []\n",
    "bestScore = 300\n",
    "\n",
    "\n",
    "for start in range(30):\n",
    "    bMotifs = GibbsSampler(DNA,k,t,N)\n",
    "    if NewScore(bMotifs) < bestScore:\n",
    "        bestScore = NewScore(bMotifs)\n",
    "        bestMotifs = bMotifs\n",
    "\n",
    "for i in bestMotifs:\n",
    "    print(i)\n",
    "print(bestScore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0005119336433572914"
      ]
     },
     "metadata": {},
     "execution_count": 1105
    }
   ],
   "source": [
    "0.0005119336433572914"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}